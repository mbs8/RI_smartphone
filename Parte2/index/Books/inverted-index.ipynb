{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import nltk   \n",
    "import time\n",
    "import glob\n",
    "import pathlib\n",
    "import requests\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "#from utils import *\n",
    "from bs4 import BeautifulSoup\n",
    "from html.parser import HTMLParser\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "agent = { 'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:50.0) Gecko/20100101 Firefox/50.0',\n",
    "          'Accept-Language': 'pt-BR'}\n",
    "\n",
    "files_path = r\"../../../Parte2/data/*/*\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most frequent Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low case only, remenber toremove non-ascii\n",
    "most_frequents = {\n",
    "    'price':['preço', 'preco'],\n",
    "    'model':['modelo'],\n",
    "    'ram':['memoria ram', 'ram', 'memória RAM'],\n",
    "    'hd':['armazenamento interno', 'memória interna', 'memoria interna', 'interna'],\n",
    "    'screen':['tamanho da tela', 'tela', 'tamanho do display', 'display', 'tamanho']\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_string(text):\n",
    "    if len(text) <= 2:\n",
    "        return False\n",
    "    if text[:3] == 'var':\n",
    "        return False\n",
    "    if text[0] == u'\\xa0':\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6836e26331664c69b5e179bf6a2703c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=434), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stores_path = glob.glob(files_path)\n",
    "dictionary  = []\n",
    "pages_dict  = []\n",
    "\n",
    "\n",
    "\n",
    "for page in tqdm(stores_path):\n",
    "    with open(page, \"r\", encoding='utf-8') as f:\n",
    "        doc= f.read()\n",
    "\n",
    "    s = BeautifulSoup(doc, \"html.parser\")\n",
    "    for script in s([\"script\", \"style\"]):\n",
    "        script.decompose()    # rip it out\n",
    "    \n",
    "    all_text = s.body.find_all(text=True)\n",
    "\n",
    "\n",
    "\n",
    "    html_page = [x for x in all_text if check_string(x)]\n",
    "    html_page = ' '.join(html_page)\n",
    "\n",
    "    clean_text = re.sub(r'[^\\w\\s$]','', html_page.lower())\n",
    "    clean_text = re.sub(r'[\\n\\t]','', clean_text)\n",
    "    #to lower case\n",
    "\n",
    "    clean_text = [text for text in clean_text.split(' ') if len(text) > 2]\n",
    "    \n",
    "    word_dict = defaultdict(lambda: 0)\n",
    "    words, counts = np.unique(clean_text, return_counts=True)\n",
    "    for word, count in zip(words, counts):\n",
    "        word_dict[word] = count\n",
    "\n",
    "    pages_dict.append(word_dict)\n",
    "\n",
    "    dictionary += list(words)\n",
    "dictionary = np.unique(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0cfc20eeea14c9f86313a20c6069084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20453), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "inverted_index = {}\n",
    "for key in tqdm(dictionary):\n",
    "    \n",
    "    inverted_index[key] = []\n",
    "    for page_idx, page_dict in enumerate(pages_dict):\n",
    "        count = page_dict[key]\n",
    "        if count > 0 :\n",
    "            inverted_index[key].append((page_idx, count))\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
