{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk   \n",
    "import unicodedata\n",
    "from html.parser import HTMLParser\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from utils import *\n",
    "import pathlib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import requests\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('text_store_label.csv')\n",
    "df = df.fillna(\" \")\n",
    "u_class = df['store'].values\n",
    "l  = df['link'].values\n",
    "X  = df['text'].values\n",
    "y  = df['label'].values\n",
    "logo = LeaveOneGroupOut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clss = [GaussianNB(), DecisionTreeClassifier(), SVC(gamma='auto'), \n",
    "        MLPClassifier(hidden_layer_sizes=(256, 64, 32)), LogisticRegression(solver='lbfgs'),\n",
    "        RandomForestClassifier(n_estimators=100, n_jobs=3)]\n",
    "\n",
    "acc_results,pre_results,rec_results = [], [], []\n",
    "metrics = ['Acuracy', 'Precision','Recall', 'Train Time']\n",
    "header = [cls.__class__.__name__ for cls in clss]\n",
    "header = [[h + \" \" + m for m in metrics] for h in header]\n",
    "header = np.array(header).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['magazineluiza', 'amazon', 'amazon', ..., 'ricardoeletro',\n",
       "       'ricardoeletro', 'ricardoeletro'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_pt = [\"de\",\"a\",\"o\",\"que\",\"e\",\"do\",\"da\",\"em\",\"um\",\"para\",\"é\",\"com\",\"não\",\"uma\",\"os\",\"no\",\n",
    "                 \"se\",\"na\",\"por\",\"mais\",\"as\",\"dos\",\"como\",\"mas\",\"foi\",\"ao\",\"ele\",\"das\",\"tem\",\"à\",\"seu\",\n",
    "                 \"sua\",\"ou\",\"ser\",\"quando\",\"muito\",\"há\",\"nos\",\"já\",\"está\",\"eu\",\"também\",\"só\",\"pelo\",\"pela\",\n",
    "                 \"até\",\"isso\",\"ela\",\"entre\",\"era\",\"depois\",\"sem\",\"mesmo\",\"aos\",\"ter\",\"seus\",\"quem\",\"nas\",\"me\",\n",
    "                 \"esse\",\"eles\",\"estão\",\"você\",\"tinha\",\"foram\",\"essa\",\"num\",\"nem\",\"suas\",\"meu\",\"às\",\"minha\",\"têm\",\n",
    "                 \"numa\",\"pelos\",\"elas\",\"havia\",\"seja\",\"qual\",\"será\",\"nós\",\"tenho\",\"lhe\",\"deles\",\"essas\",\"esses\",\n",
    "                 \"pelas\",\"este\",\"fosse\",\"dele\",\"tu\",\"te\",\"vocês\",\"vos\",\"lhes\",\"meus\",\"minhas\",\"teu\",\"tua\",\"teus\",\n",
    "                 \"tuas\",\"nosso\",\"nossa\",\"nossos\",\"nossas\",\"dela\",\"delas\",\"esta\",\"estes\",\"estas\",\"aquele\",\"aquela\",\n",
    "                 \"aqueles\",\"aquelas\",\"isto\",\"aquilo\",\"estou\",\"está\",\"estamos\",\"estão\",\"estive\",\"esteve\",\"estivemos\",\n",
    "                 \"estiveram\",\"estava\",\"estávamos\",\"estavam\",\"estivera\",\"estivéramos\",\"esteja\",\"estejamos\",\"estejam\",\n",
    "                 \"estivesse\",\"estivéssemos\",\"estivessem\",\"estiver\",\"estivermos\",\"estiverem\",\"hei\",\"há\",\"havemos\",\"hão\",\n",
    "                 \"houve\",\"houvemos\",\"houveram\",\"houvera\",\"houvéramos\",\"haja\",\"hajamos\",\"hajam\",\"houvesse\",\"houvéssemos\",\n",
    "                 \"houvessem\",\"houver\",\"houvermos\",\"houverem\",\"houverei\",\"houverá\",\"houveremos\",\"houverão\",\"houveria\",\n",
    "                 \"houveríamos\",\"houveriam\",\"sou\",\"somos\",\"são\",\"era\",\"éramos\",\"eram\",\"fui\",\"foi\",\"fomos\",\"foram\",\"fora\",\n",
    "                 \"fôramos\",\"seja\",\"sejamos\",\"sejam\",\"fosse\",\"fôssemos\",\"fossem\",\"for\",\"formos\",\"forem\",\"serei\",\"será\",\n",
    "                 \"seremos\",\"serão\",\"seria\",\"seríamos\",\"seriam\",\"tenho\",\"tem\",\"temos\",\"tém\",\"tinha\",\"tínhamos\",\"tinham\",\n",
    "                 \"tive\",\"teve\",\"tivemos\",\"tiveram\",\"tivera\",\"tivéramos\",\"tenha\",\"tenhamos\",\"tenham\",\"tivesse\",\"tivéssemos\",\n",
    "                 \"tivessem\",\"tiver\",\"tivermos\",\"tiverem\",\"terei\",\"terá\",\"teremos\",\"terão\",\"teria\",\"teríamos\",\"teriam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = [0, 1]\n",
    "for use_lowercase in opt:\n",
    "    for use_stopwords in opt:\n",
    "        stop_words = stop_words_pt if use_stopwords else None\n",
    "        for use_tfidf in tqdm(opt):\n",
    "            #print(use_lowercase, use_stopwords, use_tfidf)\n",
    "\n",
    "            final_metrics = []\n",
    "            for cls in clss:\n",
    "                text_clf = Pipeline([\n",
    "                    ('vect', CountVectorizer(lowercase=use_lowercase, stop_words=stop_words)),\n",
    "                    ('tfidf', TfidfTransformer() if use_tfidf else None),\n",
    "                    ('tranf', DenseTransformer()),\n",
    "                    ('clf', cls),\n",
    "                ])\n",
    "                model_metrics = []\n",
    "\n",
    "                for train_index, test_index in (logo.split(X, y, u_class)):\n",
    "\n",
    "                    X_train, X_test = X[train_index], X[test_index]\n",
    "                    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "                    start_time = time.time()\n",
    "                    text_clf.fit(X_train, y_train)\n",
    "                    train_time = time.time()  - start_time\n",
    "\n",
    "                    y_pred = text_clf.predict(X_test).astype(np.int)\n",
    "                    precision, recall, fscore, _ = precision_recall_fscore_support(\n",
    "                                                    y_test, y_pred, average='macro')\n",
    "\n",
    "                    acc = np.mean(y_pred == y_test)\n",
    "                    model_metrics.append([acc, precision, recall, train_time])\n",
    "\n",
    "                if final_metrics == []:\n",
    "                    final_metrics = np.array(model_metrics)\n",
    "                else:\n",
    "                    final_metrics = np.concatenate((final_metrics, model_metrics),axis=1)\n",
    "\n",
    "            results = pd.DataFrame(final_metrics,columns=header)\n",
    "            # lowercase, stop_words, tfidf\n",
    "            results.to_csv(f\"results_{use_lowercase}_{use_stopwords}_{use_tfidf}.csv\")\n",
    "            results.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file_t = np.sort(glob.glob('results_*.csv'))\n",
    "results_file = [pd.read_csv(file) for file in results_file_t]\n",
    "results_file = [file[file.columns[1:]] for file in results_file]\n",
    "header = results_file[0].columns\n",
    "header = [h.replace('Classifier', \"\") for h in header]\n",
    "clean_matrix_all = []\n",
    "for idx in range(len(results_file_t)):\n",
    "    results_file[idx].columns = header\n",
    "    clean_matrix = results_file[idx].describe().loc[['mean', 'std']]\n",
    "    clean_matrix_all.append(clean_matrix)\n",
    "    #clean_matrix.to_csv('clean_'+results_file_t[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns     = clean_matrix.columns\n",
    "index       = clean_matrix.index\n",
    "n_matrix    = len(clean_matrix_all)\n",
    "new_index   = np.array(tuple(index.values) * n_matrix)\n",
    "new_columns = columns.values#np.array(tuple(columns.values) * n_matrix)\n",
    "new_vals = np.concatenate(clean_matrix_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [v.values for v in clean_matrix_all]\n",
    "n_val = np.concatenate(tuple(values),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16, 24), (24,), (16,))"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_val.shape, new_columns.shape, new_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(n_val, columns=new_columns).to_csv(\"all_metrics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot = TPOTClassifier(verbosity=3, \n",
    "                      scoring=\"balanced_accuracy\", \n",
    "                      random_state=23, \n",
    "                      periodic_checkpoint_folder=\"tpot_mnst1.txt\", \n",
    "                      n_jobs=-1, \n",
    "                      generations=3, \n",
    "                      population_size=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = [0, 1]\n",
    "use_lowercase = True\n",
    "use_stopwords = True\n",
    "use_tfidf = False\n",
    "stop_words = stop_words_pt if use_stopwords else None\n",
    "\n",
    "final_metrics = []\n",
    "            \n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(lowercase=use_lowercase, stop_words=stop_words)),\n",
    "    ('tfidf', TfidfTransformer() if use_tfidf else None),\n",
    "    ('tranf', DenseTransformer()),\n",
    "    ('clf', tpot),\n",
    "])\n",
    "model_metrics = []\n",
    "\n",
    "for train_index, test_index in (logo.split(X, y, u_class)):\n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    start_time = time.time()\n",
    "    text_clf.fit(X_train, y_train)\n",
    "    train_time = time.time()  - start_time\n",
    "\n",
    "    y_pred = text_clf.predict(X_test).astype(np.int)\n",
    "    precision, recall, fscore, _ = precision_recall_fscore_support(\n",
    "                                    y_test, y_pred, average='macro')\n",
    "\n",
    "    acc = np.mean(y_pred == y_test)\n",
    "    model_metrics.append([acc, precision, recall, train_time])\n",
    "\n",
    "if final_metrics == []:\n",
    "    final_metrics = np.array(model_metrics)\n",
    "else:\n",
    "    final_metrics = np.concatenate((final_metrics, model_metrics),axis=1)\n",
    "\n",
    "results = pd.DataFrame(final_metrics,columns=header)\n",
    "# lowercase, stop_words, tfidf\n",
    "results.to_csv(f\"results_tpot_{use_lowercase}_{use_stopwords}_{use_tfidf}.csv\")\n",
    "results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLPClassifier Acuracy</th>\n",
       "      <th>MLPClassifier Precision</th>\n",
       "      <th>MLPClassifier Recall</th>\n",
       "      <th>MLPClassifier Train Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.893194</td>\n",
       "      <td>0.869116</td>\n",
       "      <td>0.879217</td>\n",
       "      <td>15.034539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.153287</td>\n",
       "      <td>0.169704</td>\n",
       "      <td>0.160797</td>\n",
       "      <td>1.542440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.547554</td>\n",
       "      <td>0.612319</td>\n",
       "      <td>0.515196</td>\n",
       "      <td>12.751517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.846118</td>\n",
       "      <td>0.708454</td>\n",
       "      <td>0.812147</td>\n",
       "      <td>14.042177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.978701</td>\n",
       "      <td>0.957593</td>\n",
       "      <td>0.959649</td>\n",
       "      <td>15.430089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.994842</td>\n",
       "      <td>0.988680</td>\n",
       "      <td>0.996318</td>\n",
       "      <td>16.087667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.443422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MLPClassifier Acuracy  MLPClassifier Precision  MLPClassifier Recall  \\\n",
       "count              10.000000                10.000000             10.000000   \n",
       "mean                0.893194                 0.869116              0.879217   \n",
       "std                 0.153287                 0.169704              0.160797   \n",
       "min                 0.547554                 0.612319              0.515196   \n",
       "25%                 0.846118                 0.708454              0.812147   \n",
       "50%                 0.978701                 0.957593              0.959649   \n",
       "75%                 0.994842                 0.988680              0.996318   \n",
       "max                 1.000000                 1.000000              1.000000   \n",
       "\n",
       "       MLPClassifier Train Time  \n",
       "count                 10.000000  \n",
       "mean                  15.034539  \n",
       "std                    1.542440  \n",
       "min                   12.751517  \n",
       "25%                   14.042177  \n",
       "50%                   15.430089  \n",
       "75%                   16.087667  \n",
       "max                   17.443422  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clss = [MLPClassifier(hidden_layer_sizes=(1024, 512, 256, 64, 32), learning_rate_init=0.001,early_stopping=True)]#, MLPClassifier(hidden_layer_sizes=(512, 32),early_stopping=True)  ]\n",
    "\n",
    "acc_results,pre_results,rec_results = [], [], []\n",
    "metrics = ['Acuracy', 'Precision','Recall', 'Train Time']\n",
    "header = [cls.__class__.__name__ for cls in clss]\n",
    "header = [[h + \" \" + m for m in metrics] for h in header]\n",
    "header = np.array(header).reshape(-1)\n",
    "\n",
    "\n",
    "use_lowercase = True\n",
    "use_stopwords = True\n",
    "use_tfidf = False\n",
    "stop_words = stop_words_pt if use_stopwords else None\n",
    "\n",
    "final_metrics = []\n",
    "for cls in clss:\n",
    "    text_clf = Pipeline([\n",
    "        ('vect', CountVectorizer(lowercase=use_lowercase, stop_words=stop_words)),\n",
    "        ('tfidf', TfidfTransformer() if use_tfidf else None),\n",
    "        ('tranf', DenseTransformer()),\n",
    "        ('clf', cls),\n",
    "    ])\n",
    "    model_metrics = []\n",
    "\n",
    "    for train_index, test_index in tqdm(logo.split(X, y, u_class)):\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        start_time = time.time()\n",
    "        text_clf.fit(X_train, y_train)\n",
    "        train_time = time.time()  - start_time\n",
    "\n",
    "        y_pred = text_clf.predict(X_test).astype(np.int)\n",
    "        precision, recall, fscore, _ = precision_recall_fscore_support(\n",
    "                                        y_test, y_pred, average='macro')\n",
    "\n",
    "        acc = np.mean(y_pred == y_test)\n",
    "        model_metrics.append([acc, precision, recall, train_time])\n",
    "\n",
    "    if final_metrics == []:\n",
    "        final_metrics = np.array(model_metrics)\n",
    "    else:\n",
    "        final_metrics = np.concatenate((final_metrics, model_metrics),axis=1)\n",
    "\n",
    "results = pd.DataFrame(final_metrics,columns=header)\n",
    "# lowercase, stop_words, tfidf\n",
    "results.to_csv(f\"results_mlp_a_{use_lowercase}_{use_stopwords}_{use_tfidf}.csv\")\n",
    "results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "pipe = Pipeline([('classifier' , LogisticRegression())])\n",
    "param_grid = [\n",
    "    {'classifier' : [LogisticRegression()],\n",
    "     'classifier__penalty' : ['l2'],\n",
    "    'classifier__C' : np.logspace(-4, 4, 20),\n",
    "    'classifier__solver' : ['liblinear','lbfgs']},]\n",
    "\n",
    "# Create grid search object\n",
    "\n",
    "clf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   16.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   14.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 193 out of 200 | elapsed:   14.3s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   15.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   11.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   14.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   11.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   14.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   12.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 144 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    8.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   14.5s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GridSearchCV Acuracy</th>\n",
       "      <th>GridSearchCV Precision</th>\n",
       "      <th>GridSearchCV Recall</th>\n",
       "      <th>GridSearchCV Train Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.908806</td>\n",
       "      <td>0.899356</td>\n",
       "      <td>0.892291</td>\n",
       "      <td>13.408756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.158033</td>\n",
       "      <td>0.156045</td>\n",
       "      <td>0.165760</td>\n",
       "      <td>2.390862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.532609</td>\n",
       "      <td>0.602210</td>\n",
       "      <td>0.515196</td>\n",
       "      <td>8.241345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.922106</td>\n",
       "      <td>0.924313</td>\n",
       "      <td>0.871382</td>\n",
       "      <td>12.071824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.986713</td>\n",
       "      <td>0.968815</td>\n",
       "      <td>0.973473</td>\n",
       "      <td>14.121754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.995781</td>\n",
       "      <td>0.991011</td>\n",
       "      <td>0.997007</td>\n",
       "      <td>14.501750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.709162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       GridSearchCV Acuracy  GridSearchCV Precision  GridSearchCV Recall  \\\n",
       "count             10.000000               10.000000            10.000000   \n",
       "mean               0.908806                0.899356             0.892291   \n",
       "std                0.158033                0.156045             0.165760   \n",
       "min                0.532609                0.602210             0.515196   \n",
       "25%                0.922106                0.924313             0.871382   \n",
       "50%                0.986713                0.968815             0.973473   \n",
       "75%                0.995781                0.991011             0.997007   \n",
       "max                1.000000                1.000000             1.000000   \n",
       "\n",
       "       GridSearchCV Train Time  \n",
       "count                10.000000  \n",
       "mean                 13.408756  \n",
       "std                   2.390862  \n",
       "min                   8.241345  \n",
       "25%                  12.071824  \n",
       "50%                  14.121754  \n",
       "75%                  14.501750  \n",
       "max                  16.709162  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clss = [clf]\n",
    "\n",
    "acc_results,pre_results,rec_results = [], [], []\n",
    "metrics = ['Acuracy', 'Precision','Recall', 'Train Time']\n",
    "header = [cls.__class__.__name__ for cls in clss]\n",
    "header = [[h + \" \" + m for m in metrics] for h in header]\n",
    "header = np.array(header).reshape(-1)\n",
    "\n",
    "\n",
    "use_lowercase = True\n",
    "use_stopwords = True\n",
    "use_tfidf = False\n",
    "stop_words = stop_words_pt if use_stopwords else None\n",
    "\n",
    "final_metrics = []\n",
    "for cls in clss:\n",
    "    text_clf = Pipeline([\n",
    "        ('vect', CountVectorizer(lowercase=use_lowercase, stop_words=stop_words)),\n",
    "        ('tfidf', TfidfTransformer() if use_tfidf else None),\n",
    "        ('tranf', DenseTransformer()),\n",
    "        ('clf', cls),\n",
    "    ])\n",
    "    model_metrics = []\n",
    "\n",
    "    for train_index, test_index in (logo.split(X, y, u_class)):\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        start_time = time.time()\n",
    "        text_clf.fit(X_train, y_train)\n",
    "        train_time = time.time()  - start_time\n",
    "\n",
    "        y_pred = text_clf.predict(X_test).astype(np.int)\n",
    "        precision, recall, fscore, _ = precision_recall_fscore_support(\n",
    "                                        y_test, y_pred, average='macro')\n",
    "\n",
    "        acc = np.mean(y_pred == y_test)\n",
    "        model_metrics.append([acc, precision, recall, train_time])\n",
    "\n",
    "    if final_metrics == []:\n",
    "        final_metrics = np.array(model_metrics)\n",
    "    else:\n",
    "        final_metrics = np.concatenate((final_metrics, model_metrics),axis=1)\n",
    "\n",
    "results = pd.DataFrame(final_metrics,columns=header)\n",
    "# lowercase, stop_words, tfidf\n",
    "results.to_csv(f\"results_mlp_{use_lowercase}_{use_stopwords}_{use_tfidf}.csv\")\n",
    "results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pipeline Acuracy</th>\n",
       "      <th>Pipeline Precision</th>\n",
       "      <th>Pipeline Recall</th>\n",
       "      <th>Pipeline Train Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.899640</td>\n",
       "      <td>0.895743</td>\n",
       "      <td>0.868074</td>\n",
       "      <td>0.063229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.156885</td>\n",
       "      <td>0.154544</td>\n",
       "      <td>0.173888</td>\n",
       "      <td>0.012108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.532609</td>\n",
       "      <td>0.602210</td>\n",
       "      <td>0.515196</td>\n",
       "      <td>0.048243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.880486</td>\n",
       "      <td>0.923609</td>\n",
       "      <td>0.758142</td>\n",
       "      <td>0.053342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.977971</td>\n",
       "      <td>0.956534</td>\n",
       "      <td>0.978060</td>\n",
       "      <td>0.060979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.995781</td>\n",
       "      <td>0.991011</td>\n",
       "      <td>0.997173</td>\n",
       "      <td>0.072081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pipeline Acuracy  Pipeline Precision  Pipeline Recall  \\\n",
       "count         10.000000           10.000000        10.000000   \n",
       "mean           0.899640            0.895743         0.868074   \n",
       "std            0.156885            0.154544         0.173888   \n",
       "min            0.532609            0.602210         0.515196   \n",
       "25%            0.880486            0.923609         0.758142   \n",
       "50%            0.977971            0.956534         0.978060   \n",
       "75%            0.995781            0.991011         0.997173   \n",
       "max            1.000000            1.000000         1.000000   \n",
       "\n",
       "       Pipeline Train Time  \n",
       "count            10.000000  \n",
       "mean              0.063229  \n",
       "std               0.012108  \n",
       "min               0.048243  \n",
       "25%               0.053342  \n",
       "50%               0.060979  \n",
       "75%               0.072081  \n",
       "max               0.083267  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clss = [clf.best_estimator_]\n",
    "header = [cls.__class__.__name__ for cls in clss]\n",
    "header = [[h + \" \" + m for m in metrics] for h in header]\n",
    "header = np.array(header).reshape(-1)\n",
    "\n",
    "\n",
    "text_clf = Pipeline([\n",
    "        ('vect', CountVectorizer(lowercase=use_lowercase, stop_words=stop_words)),\n",
    "        ('tfidf', TfidfTransformer() if use_tfidf else None),\n",
    "        ('tranf', DenseTransformer()),\n",
    "        ('clf', clss[0]),\n",
    "    ])\n",
    "model_metrics = []\n",
    "for train_index, test_index in (logo.split(X, y, u_class)):\n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    start_time = time.time()\n",
    "    text_clf.fit(X_train, y_train)\n",
    "    train_time = time.time()  - start_time\n",
    "\n",
    "    y_pred = text_clf.predict(X_test).astype(np.int)\n",
    "    precision, recall, fscore, _ = precision_recall_fscore_support(\n",
    "                                    y_test, y_pred, average='macro')\n",
    "\n",
    "    acc = np.mean(y_pred == y_test)\n",
    "    model_metrics.append([acc, precision, recall, train_time])\n",
    "\n",
    "results = pd.DataFrame(model_metrics,columns=header)\n",
    "results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'page_clf3.sav'\n",
    "pickle.dump(text_clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "pipe = Pipeline([('classifier' , LogisticRegression())])\n",
    "param_grid = [\n",
    "    {'classifier' : [LogisticRegression()],\n",
    "     'classifier__penalty' : ['l1', 'l2'],\n",
    "    'classifier__C' : np.logspace(-4, 4, 20),\n",
    "    'classifier__solver' : ['liblinear']},]\n",
    "\n",
    "# Create grid search object\n",
    "\n",
    "clf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
